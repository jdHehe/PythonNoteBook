{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow的基本的操作函数的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  利用tf.cond  tf.case进行if语句类似的操作\n",
    "x = tf.random_uniform([])\n",
    "y = tf.random_uniform([])\n",
    "out = tf.cond(tf.greater(x, y), lambda: x+y, lambda: x-y)\n",
    "print(sess.run(out))\n",
    "\n",
    "x = tf.random_uniform([], -1, 1)\n",
    "y = tf.random_uniform([], -1, 1)\n",
    "out = tf.case({tf.less(x, y): lambda: tf.add(x, y),\n",
    "              tf.greater(x, y): lambda: tf.subtract(x, y)},\n",
    "              default=lambda: tf.constant(0.0), exclusive=True)\n",
    "print(sess.run(out))\n",
    "#  利用tf.equal 进行矩阵每个元素的比较element-wise\n",
    "x = tf.Variable([[0, -2, -1], [0, 1, 2]])\n",
    "y = tf.zeros_like(x)\n",
    "out = tf.equal(x,y)\n",
    "sess.run(x.initializer)  #变量需要先进行初始化操作  initializer \n",
    "print(sess.run(out))\n",
    "\n",
    "#  利用tf.greater 将float32的数组转化为True False的矩阵  tf.where接受bool的矩阵，返回表示 True的位置的ndArray\n",
    "#  利用tf.gather  将指定矩阵中相关下标的元素提取出来 \n",
    "x = tf.Variable([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "                 30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "                 34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "                 27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "                 33.71149445,  28.59134293,  36.05556488,  28.66994858])\n",
    "y = tf.greater(x, 30)\n",
    "indices = tf.where(y)  #或者直接使用 tf.where(x > 30)\n",
    "elements = tf.gather(x, indices=indices)\n",
    "\n",
    "sess.run(x.initializer)  #变量需要先进行初始化操作  initializer \n",
    "print(sess.run(indices))\n",
    "print(sess.run(elements))\n",
    "\n",
    "# 构造符合要求的对角矩阵\n",
    "digEle = tf.range(start=1, limit=7, delta=1)\n",
    "digTensor = tf.diag(digEle)\n",
    "print(sess.run(digTensor))\n",
    "\n",
    "# 计算矩阵的行列式\n",
    "x = tf.random_uniform([10,10], -1, 1)\n",
    "out = tf.matrix_determinant(x)\n",
    "sess.run(out)\n",
    "\n",
    "# 发现tensor中unique的元素\n",
    "x = tf.Variable([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\n",
    "out = tf.unique(x)\n",
    "sess.run(x.initializer)\n",
    "sess.run(out)\n",
    "\n",
    "# Huber loss function \n",
    "x = tf.random_uniform([300], -4, 4)\n",
    "y = tf.random_uniform([300], -4, 4)\n",
    "average = tf.reduce_mean(x-y)\n",
    "out1 = tf.reduce_mean(tf.square(x-y))\n",
    "out2 = tf.reduce_sum(tf.abs(x-y))\n",
    "out = tf.cond(average>0, lambda:out1, lambda:out2)\n",
    "print(sess.run(out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ca51a1b6937c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/birth_life_2010.txt'\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "X, Y = tf.placeholder(tf.float32, name='birthRate'),  tf.placeholder(tf.float32, name='lifeExpectancy')\n",
    "w, b = tf.get_variable(initializer=0.0, name='weight'), tf.get_variable(initializer=0.0, name='biaes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = X*w + b\n",
    "loss = tf.square(y_predict-Y, name='loss')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:1661.863764550287\n",
      "Epoch 1:956.3224439573916\n",
      "Epoch 2:844.6737683409139\n",
      "Epoch 3:750.7312372197838\n",
      "Epoch 4:667.659830722252\n",
      "Epoch 5:594.1417484349327\n",
      "Epoch 6:529.0787271179651\n",
      "Epoch 7:471.5003584364135\n",
      "Epoch 8:420.5458252520938\n",
      "Epoch 9:375.45531067297253\n",
      "Epoch 10:335.55436177954664\n",
      "Epoch 11:300.24627770512666\n",
      "Epoch 12:269.00374521501146\n",
      "Epoch 13:241.3595776562824\n",
      "Epoch 14:216.9003910217238\n",
      "Epoch 15:195.25972397061292\n",
      "Epoch 16:176.1137731664483\n",
      "Epoch 17:159.17551683403158\n",
      "Epoch 18:144.19069889799545\n",
      "Epoch 19:130.93503690609023\n",
      "Epoch 20:119.20935661137888\n",
      "Epoch 21:108.83793506244884\n",
      "Epoch 22:99.66458668207358\n",
      "Epoch 23:91.55171666162971\n",
      "Epoch 24:84.37658985632197\n",
      "Epoch 25:78.03213362396008\n",
      "Epoch 26:72.42178616552172\n",
      "Epoch 27:67.46132107331957\n",
      "Epoch 28:63.07563027821873\n",
      "Epoch 29:59.19871881428714\n",
      "Epoch 30:55.77163058824279\n",
      "Epoch 31:52.742706123048954\n",
      "Epoch 32:50.06563247971506\n",
      "Epoch 33:47.70006537150391\n",
      "Epoch 34:45.61017402416389\n",
      "Epoch 35:43.763794843404014\n",
      "Epoch 36:42.13259061904698\n",
      "Epoch 37:40.692217106133775\n",
      "Epoch 38:39.420219863367905\n",
      "Epoch 39:38.297008645340895\n",
      "Epoch 40:37.305592010505066\n",
      "Epoch 41:36.43066341609841\n",
      "Epoch 42:35.658454647898296\n",
      "Epoch 43:34.977248985403655\n",
      "Epoch 44:34.376551568753236\n",
      "Epoch 45:33.846705867195695\n",
      "Epoch 46:33.37967463995998\n",
      "Epoch 47:32.9680108638946\n",
      "Epoch 48:32.60548541990942\n",
      "Epoch 49:32.28618434173986\n",
      "Epoch 50:32.004961317298495\n",
      "Epoch 51:31.75752976890163\n",
      "Epoch 52:31.53978877073019\n",
      "Epoch 53:31.34836144135732\n",
      "Epoch 54:31.180118720635072\n",
      "Epoch 55:31.03225782010038\n",
      "Epoch 56:30.902463045723714\n",
      "Epoch 57:30.788599823501748\n",
      "Epoch 58:30.68872023182676\n",
      "Epoch 59:30.60122912194102\n",
      "Epoch 60:30.524589418089263\n",
      "Epoch 61:30.457532704476954\n",
      "Epoch 62:30.398964531451316\n",
      "Epoch 63:30.34777825418737\n",
      "Epoch 64:30.303121465726413\n",
      "Epoch 65:30.264247165074092\n",
      "Epoch 66:30.230395186190357\n",
      "Epoch 67:30.200965440111528\n",
      "Epoch 68:30.175501555469697\n",
      "Epoch 69:30.153343991707324\n",
      "Epoch 70:30.134226098457216\n",
      "Epoch 71:30.117758308603477\n",
      "Epoch 72:30.103543774372174\n",
      "Epoch 73:30.091394110470336\n",
      "Epoch 74:30.08093890536509\n",
      "Epoch 75:30.072084357345624\n",
      "Epoch 76:30.06452434975899\n",
      "Epoch 77:30.0581486002297\n",
      "Epoch 78:30.05278219980139\n",
      "Epoch 79:30.04828310612785\n",
      "Epoch 80:30.04458791257593\n",
      "Epoch 81:30.041549566215345\n",
      "Epoch 82:30.039046151249817\n",
      "Epoch 83:30.037039793959796\n",
      "Epoch 84:30.035464155240486\n",
      "Epoch 85:30.034287342776263\n",
      "Epoch 86:30.033386764163456\n",
      "Epoch 87:30.03276857610855\n",
      "Epoch 88:30.032388654677273\n",
      "Epoch 89:30.032152204158926\n",
      "Epoch 90:30.03209388247043\n",
      "Epoch 91:30.03219517776896\n",
      "Epoch 92:30.032402951199575\n",
      "Epoch 93:30.03264380555698\n",
      "Epoch 94:30.033044778692265\n",
      "Epoch 95:30.03343712379727\n",
      "Epoch 96:30.033913317535955\n",
      "Epoch 97:30.03442924663878\n",
      "Epoch 98:30.0349335548615\n",
      "Epoch 99:30.03552558278714\n",
      "before sess.run(w.eval()), sess.run(b.eval())  <class 'tensorflow.python.ops.variables.Variable'> <class 'tensorflow.python.ops.variables.Variable'>\n",
      "-6.0702143 84.92951\n",
      "Took: 5.808332 secinds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(w.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    for i  in range(100):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            _, Loss = sess.run([optimizer, loss], feed_dict={X:x, Y:y})  #在Session中运行优化函数\n",
    "            total_loss += Loss\n",
    "        print('Epoch {0}:{1}'.format(i, total_loss/n_samples))\n",
    "    print('before sess.run(w.eval()), sess.run(b.eval()) ', type(w), type(b))\n",
    "    w_out, b_out = sess.run([w, b])\n",
    "    print(w_out, b_out)\n",
    "print('Took: %f secinds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "#  设置一些参数\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "\n",
    "# Step1: Read in data\n",
    "mnist_folder = 'data/mnist'\n",
    "# utils.download_mnist(mnist_folder)\n",
    "train, vl, test = utils.read_mnist(mnist_folder, flatten=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'> <TensorSliceDataset shapes: ((784,), (10,)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "# print(type(train_data), train_data)\n",
    "train_data = train_data.shuffle(10000) \n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  根据输出的类型个输出的shape声明一种构建Iterator的op， 之后可以通过这种op创建不同的Iterator\n",
    "iterator   = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init  = iterator.make_initializer(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = tf.random_normal(shape=[img.shape[1].value, label.shape[1].value], stddev=0.01), tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  设定模型训练的 相关计算graph 节点\n",
    "logits = tf.matmul(img, w) + b\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.04).minimize(loss)\n",
    "\n",
    "# 设定进行模型测试的计算 graph相关节点\n",
    "preds = tf.nn.softmax(logits=logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 2.3065511747848157\n",
      "Average loss epoch 1: 2.30641984884129\n",
      "Average loss epoch 2: 2.3058686311854872\n",
      "Average loss epoch 3: 2.306882260012072\n",
      "Average loss epoch 4: 2.3064788907073264\n",
      "Average loss epoch 5: 2.307871914464374\n",
      "Average loss epoch 6: 2.306815458452979\n",
      "Average loss epoch 7: 2.305905438578406\n",
      "Average loss epoch 8: 2.307660339599432\n",
      "Average loss epoch 9: 2.3073361884715946\n",
      "Average loss epoch 10: 2.307914221009543\n",
      "Average loss epoch 11: 2.307437108838281\n",
      "Average loss epoch 12: 2.3073619526486064\n",
      "Average loss epoch 13: 2.306532701226168\n",
      "Average loss epoch 14: 2.3070415840592493\n",
      "Average loss epoch 15: 2.3060637773469437\n",
      "Average loss epoch 16: 2.3069913647895635\n",
      "Average loss epoch 17: 2.3077291350032008\n",
      "Average loss epoch 18: 2.3064806028854017\n",
      "Average loss epoch 19: 2.3046940359958383\n",
      "Average loss epoch 20: 2.30655085486035\n",
      "Average loss epoch 21: 2.3072333629741224\n",
      "Average loss epoch 22: 2.306486851670021\n",
      "Average loss epoch 23: 2.3078240932420244\n",
      "Average loss epoch 24: 2.30706395104874\n",
      "Average loss epoch 25: 2.3061280816100362\n",
      "Average loss epoch 26: 2.3058468508165935\n",
      "Average loss epoch 27: 2.3050488937732787\n",
      "Average loss epoch 28: 2.3069950347722963\n",
      "Average loss epoch 29: 2.3063586390295696\n",
      "Total time: 21.359067916870117 seconds\n",
      "Accuracy 0.1065\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer()) #tf变量初始化\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        sess.run(train_init)   #通过iterator从训练数据集train_data中拉取数据\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, Loss = sess.run([optimizer, loss])\n",
    "                total_loss += Loss\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    \n",
    "    sess.run(test_init)\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.0\n",
      "13789.117\n",
      "128.0\n",
      "13187.484\n",
      "128.0\n",
      "12449.947\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "out = tf.reduce_sum(img)\n",
    "label_out = tf.reduce_sum(label)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(train_init)\n",
    "    print(sess.run(label_out))\n",
    "    sess.run(img)\n",
    "    print(sess.run(out))\n",
    "    print(sess.run(label_out))\n",
    "    sess.run(img) \n",
    "    print(sess.run(out))\n",
    "    print(sess.run(label_out))\n",
    "    sess.run(img)\n",
    "    print(sess.run(out))\n",
    "    print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
